{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b12accf8-09de-46f0-b176-18ddeed046f4",
   "metadata": {},
   "source": [
    "# BERT Model Deployment on Amazon SageMaker\n",
    "\n",
    "In the pretrained-torch-example lab we utilize the AWS Boto3 Python SDK to orchestrate deployment on SageMaker. There are simpler methods of deployment with the SageMaker Python SDK for out of the box pre-trained models such as BERT. When models such as BERT are available directly via the HuggingFace Hub we can take the automated code provided on the model dashboard for deployment using the Python SDK:\n",
    "\n",
    "![HF-Hub Image](images/hf-hub-deployment.png)\n",
    "\n",
    "Note that you should still use the Boto3 SDK when it makes sense, it also helps to have the lower level API calls to have full understanding of the flow of creation in SageMaker especially when it comes to more complex use-cases. To understand the difference between both SDKs please reference this [blog](https://towardsdatascience.com/sagemaker-python-sdk-vs-boto3-sdk-45c424e8e250)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a164f7-1b2b-4e2c-818c-ff183f737dc4",
   "metadata": {},
   "source": [
    "## Example Code with SageMaker Python SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b59172-54b3-4690-9465-97c96017dae5",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75cb61fd-5cf6-42d4-8a5c-6e24c1645349",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2883e98-ef90-40a6-9c65-d8937f782c5a",
   "metadata": {},
   "source": [
    "### SageMaker Model Object\n",
    "\n",
    "In this case providing the transformers image and pytorch version by default will pull down the container image for you. Unlike when you use the Boto3 SDK you have to specifically provide the container image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f28d8b95-8b15-4d09-a4d6-f66e0dd7eb98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "    'HF_MODEL_ID':'bert-base-uncased',\n",
    "    'HF_TASK':'fill-mask'\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    transformers_version='4.26.0',\n",
    "    pytorch_version='1.13.1',\n",
    "    py_version='py39',\n",
    "    env=hub,\n",
    "    role=role, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1f8763-77f5-4fa4-8aa1-808f4b4f87ad",
   "metadata": {},
   "source": [
    "### Deployment & Inference\n",
    "We directly deploy the Model object to a SageMaker endpoint, the parts that are abstracted out for us here are the create_model and create_endpoint_config API call, but if you take a look at the console you will see that both have already been created for you-\n",
    "\n",
    "<b>SageMaker Model Object</b>:\n",
    "\n",
    "<div style=\"display: flex;\">\n",
    "    <img src=\"images/hf-model-one.png\" alt=\"hf-model-one\" style=\"width: 50%; height: auto;\">\n",
    "    <img src=\"images/hf-model-two.png\" alt=\"hf-model-two\" style=\"width: 50%; height: auto;\">\n",
    "</div>\n",
    "\n",
    "<b>SageMaker EPC Object</b>:\n",
    "\n",
    "![hf-epc](images/hf-epc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc525e35-744a-47d7-bae4-432e591ca852",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1, # number of instances\n",
    "    instance_type='ml.m5.xlarge' # ec2 instance type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b68a786-8734-46e6-ad87-02b833a90795",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.16963981091976166,\n",
       "  'token': 2053,\n",
       "  'token_str': 'no',\n",
       "  'sequence': 'the answer to the universe is no.'},\n",
       " {'score': 0.07344783842563629,\n",
       "  'token': 2498,\n",
       "  'token_str': 'nothing',\n",
       "  'sequence': 'the answer to the universe is nothing.'},\n",
       " {'score': 0.05803249776363373,\n",
       "  'token': 2748,\n",
       "  'token_str': 'yes',\n",
       "  'sequence': 'the answer to the universe is yes.'},\n",
       " {'score': 0.043957870453596115,\n",
       "  'token': 4242,\n",
       "  'token_str': 'unknown',\n",
       "  'sequence': 'the answer to the universe is unknown.'},\n",
       " {'score': 0.040157340466976166,\n",
       "  'token': 3722,\n",
       "  'token_str': 'simple',\n",
       "  'sequence': 'the answer to the universe is simple.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict({\n",
    "\t\"inputs\": \"The answer to the universe is [MASK].\",\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
